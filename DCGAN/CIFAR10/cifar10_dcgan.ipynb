{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DCGAN for CIFAR10 image generation\n",
    "#### Original Paper (DCGAN): https://arxiv.org/pdf/1511.06434\n",
    "#### Implementation by Zach D."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from IPython.display import clear_output, Image\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slight modification made to GAN architecture to make network work with 32x32 images instead of 64x64 like in the original paper.\n",
    "\n",
    "Create the generator and discriminator networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_generator():\n",
    "    dropout_prob = .4\n",
    "\n",
    "    net = tf.keras.Sequential()\n",
    "    net.add(tf.keras.layers.Dense(2*2*256, input_shape=(100,)))\n",
    "    net.add(tf.keras.layers.Reshape(target_shape=(2, 2, 256)))\n",
    "    net.add(tf.keras.layers.BatchNormalization())\n",
    "    net.add(tf.keras.layers.LeakyReLU(0.2)) # size = 2x2\n",
    "    net.add(tf.keras.layers.Dropout(dropout_prob))\n",
    "    \n",
    "    net.add(tf.keras.layers.Conv2DTranspose(filters=128, kernel_size=5, strides=(2, 2), padding='same'))\n",
    "    net.add(tf.keras.layers.BatchNormalization())\n",
    "    net.add(tf.keras.layers.LeakyReLU(0.2)) # size = 4x4\n",
    "    net.add(tf.keras.layers.Dropout(dropout_prob))\n",
    "    \n",
    "    net.add(tf.keras.layers.Conv2DTranspose(filters=64, kernel_size=5, strides=(2, 2), padding='same'))\n",
    "    net.add(tf.keras.layers.BatchNormalization())\n",
    "    net.add(tf.keras.layers.LeakyReLU(0.2)) # size = 8x8\n",
    "    net.add(tf.keras.layers.Dropout(dropout_prob))\n",
    "    \n",
    "    net.add(tf.keras.layers.Conv2DTranspose(filters=32, kernel_size=5, strides=(2, 2), padding='same'))\n",
    "    net.add(tf.keras.layers.BatchNormalization())\n",
    "    net.add(tf.keras.layers.LeakyReLU(0.2)) # size = 16x16\n",
    "    net.add(tf.keras.layers.Dropout(dropout_prob))\n",
    "    \n",
    "    net.add(tf.keras.layers.Conv2DTranspose(filters=3, kernel_size=5, strides=(2, 2), padding='same'))\n",
    "    net.add(tf.keras.layers.Activation('sigmoid')) # size = 32x32\n",
    "    \n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_discriminator():\n",
    "    dropout_prob = .4\n",
    "    net = tf.keras.Sequential()\n",
    "    net.add(tf.keras.layers.Conv2D(filters=32, kernel_size=5, padding='same', input_shape=(32, 32, 3)))\n",
    "    net.add(tf.keras.layers.LeakyReLU(0.2)) # size = 32x32\n",
    "    net.add(tf.keras.layers.Dropout(dropout_prob))\n",
    "    \n",
    "    net.add(tf.keras.layers.Conv2D(filters=64, kernel_size=5, padding='same'))\n",
    "    net.add(tf.keras.layers.BatchNormalization())\n",
    "     # size = 32x32\n",
    "    net.add(tf.keras.layers.Dropout(dropout_prob))\n",
    "    \n",
    "    net.add(tf.keras.layers.Conv2D(filters=128, kernel_size=5, strides=(2, 2), padding='same'))\n",
    "    net.add(tf.keras.layers.BatchNormalization())\n",
    "    net.add(tf.keras.layers.LeakyReLU(0.2)) # size = 16x16\n",
    "    net.add(tf.keras.layers.Dropout(dropout_prob))\n",
    "    \n",
    "    net.add(tf.keras.layers.Conv2D(filters=256, kernel_size=5, strides=(2, 2), padding='same'))\n",
    "    net.add(tf.keras.layers.BatchNormalization())\n",
    "    net.add(tf.keras.layers.LeakyReLU(0.2)) # size = 8x8\n",
    "    net.add(tf.keras.layers.Dropout(dropout_prob))\n",
    "    \n",
    "    net.add(tf.keras.layers.Flatten())\n",
    "    net.add(tf.keras.layers.Dense(1))\n",
    "    net.add(tf.keras.layers.Activation('sigmoid'))\n",
    "    \n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a trainable discriminator, as well as the full GAN architecture with the discriminator frozen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_net = create_discriminator()\n",
    "g_net = create_generator()\n",
    "\n",
    "d_model = tf.keras.Sequential([d_net])\n",
    "d_optim = tf.keras.optimizers.Adam(lr=0.000008, decay=1e-10)\n",
    "d_model.compile(optimizer=d_optim, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "for layer in d_net.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "gan_model = tf.keras.Sequential([g_net, d_net])\n",
    "gan_optim = tf.keras.optimizers.Adam(lr=0.00004, decay=1e-10)\n",
    "gan_model.compile(optimizer=gan_optim, loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "(x_train, _), (_,_) = tf.keras.datasets.cifar10.load_data()\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_fn(image):\n",
    "    x = tf.reshape(tf.cast(image, tf.float32), (32,32,3))\n",
    "    x /= 255\n",
    "#     x = 2*x/255 - 1 # convert image to [-1, 1] range\n",
    "    x = tf.image.random_flip_left_right(x)\n",
    "    x = tf.image.random_hue(x, 0.08)\n",
    "    x = tf.image.random_saturation(x, 0.6, 1.6)\n",
    "    x = tf.image.random_brightness(x, 0.05)\n",
    "    x = tf.image.random_contrast(x, 0.7, 1.3)\n",
    "    return x\n",
    "\n",
    "real_ds = tf.data.Dataset.from_tensor_slices(x_train)\n",
    "real_ds = real_ds.shuffle(60000)\n",
    "real_ds = real_ds.repeat()\n",
    "real_ds = real_ds.apply(tf.data.experimental.map_and_batch(\n",
    "        preprocess_fn, batch_size, num_parallel_batches=6, drop_remainder=True))\n",
    "real_ds = real_ds.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtime = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "os.mkdir(dtime)\n",
    "os.mkdir(dtime + \"/imgs\")\n",
    "os.mkdir(dtime + \"/weights\")\n",
    "\n",
    "real_iter = real_ds.make_one_shot_iterator()  \n",
    "\n",
    "for i in range(0,10000):\n",
    "    # Grab a batch of real data\n",
    "    real_batch = real_iter.get_next()\n",
    "    # Make a batch of fake data by feeding the generator some noise and taking its output\n",
    "    noise = np.random.uniform(-1.0, 1.0, size=(batch_size, 100,))\n",
    "    fake_batch = g_net.predict(noise, batch_size=batch_size)\n",
    "\n",
    "    # Create the labels for each set of data (0 for fake, 1 for real)\n",
    "    real_labels = np.ones([batch_size])\n",
    "    fake_labels = np.zeros([batch_size])\n",
    "    # Train discriminator on real and fake data\n",
    "    d_fake_stats = d_model.train_on_batch(fake_batch, fake_labels)\n",
    "    d_real_stats = d_model.train_on_batch(real_batch, real_labels)\n",
    "        \n",
    "    d_loss_avg = (d_real_stats[0] + d_fake_stats[0])/2\n",
    "    d_acc_avg = (d_real_stats[1] + d_fake_stats[1])/2\n",
    "    \n",
    "    # Train the generator on noise\n",
    "    # We want the generator to fool the discriminator, therefore\n",
    "    # the generator has succeeded when the output of the GAN is 1\n",
    "    noise = np.random.uniform(-1.0, 1.0, size=(batch_size, 100,))\n",
    "    y = np.ones([batch_size])\n",
    "    g_stats = gan_model.train_on_batch(noise, y)\n",
    "    \n",
    "    # Save weights and save generator output\n",
    "    if i % 100 == 0:\n",
    "        #sample image\n",
    "        rand_n = random.randint(0,batch_size-1)\n",
    "        plt.figure(num=None, figsize=(3, 2), dpi=80, facecolor='w', edgecolor='k')\n",
    "        plt.axis('off')\n",
    "        plt.imshow(fake_batch[rand_n])\n",
    "        plt.savefig(f\"{dtime}/imgs/epoch_{i*batch_size//60000}_step_{i}.png\", bbox_inches='tight', pad_inches = 0)\n",
    "        plt.close()\n",
    "        #save weights\n",
    "        d_net.save(f\"{dtime}/weights/d_net_{i}.h5\")\n",
    "        g_net.save(f'{dtime}/weights/g_net_{i}.h5')\n",
    "\n",
    "    \n",
    "#     print(f\"[{i*batch_size//60000}  {i}/{60000//batch_size}]: [Dis. loss: {d_loss_avg}, acc: {d_acc_avg}] [Gen. loss: {g_stats[0]}, acc: {g_stats[1]}]\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print some results\n",
    "\n",
    "noise = np.random.uniform(-1.0, 1.0, size=(batch_size, 100,))\n",
    "fake_batch = g_net.predict(noise, batch_size=batch_size)\n",
    "\n",
    "fig = plt.figure(figsize=(12,12))\n",
    "for i in range(0, 100):\n",
    "    rand_n = random.randint(0,batch_size-1)\n",
    "    plt.axis('off')\n",
    "    ax1 = fig.add_subplot(10,10,i+1)\n",
    "    ax1.imshow(fake_batch[rand_n])\n",
    "plt.axis('off')\n",
    "plt.savefig(f\"results.png\", bbox_inches = 'tight',\n",
    "    pad_inches = 0)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
